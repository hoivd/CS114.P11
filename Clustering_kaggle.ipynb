{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10260822,"sourceType":"datasetVersion","datasetId":6347359},{"sourceId":10261185,"sourceType":"datasetVersion","datasetId":6347613}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torchvision.transforms import ToTensor\nimport cv2\nimport torch\nfrom sklearn.cluster import DBSCAN\nfrom tensorflow.keras.utils import load_img\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom torchvision.transforms import ToTensor, Compose, Resize\nfrom math import ceil\nfrom tensorflow.keras.applications import MobileNet\nfrom PIL import Image, UnidentifiedImageError\nimport tensorflow as tf\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\nfrom tensorflow.keras.layers import Flatten\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T23:22:14.128869Z","iopub.execute_input":"2024-12-21T23:22:14.129255Z","iopub.status.idle":"2024-12-21T23:22:14.134169Z","shell.execute_reply.started":"2024-12-21T23:22:14.129219Z","shell.execute_reply":"2024-12-21T23:22:14.133270Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = MobileNet(weights=\"imagenet\", include_top=False, pooling=\"avg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T23:22:14.625972Z","iopub.execute_input":"2024-12-21T23:22:14.626319Z","iopub.status.idle":"2024-12-21T23:22:15.794962Z","shell.execute_reply.started":"2024-12-21T23:22:14.626289Z","shell.execute_reply":"2024-12-21T23:22:15.793926Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"TensorFlow version:\", tf.__version__)\nprint(\"GPU available:\", tf.config.list_physical_devices('GPU'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T23:22:15.796198Z","iopub.execute_input":"2024-12-21T23:22:15.796528Z","iopub.status.idle":"2024-12-21T23:22:15.801814Z","shell.execute_reply.started":"2024-12-21T23:22:15.796503Z","shell.execute_reply":"2024-12-21T23:22:15.801005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"car_data= pd.read_csv('/kaggle/input/cardata-dir/CarDataset.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T23:22:16.701412Z","iopub.execute_input":"2024-12-21T23:22:16.701727Z","iopub.status.idle":"2024-12-21T23:22:16.735803Z","shell.execute_reply.started":"2024-12-21T23:22:16.701701Z","shell.execute_reply":"2024-12-21T23:22:16.734837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"col_name= ['Dir', 'Category']\ncar_data.columns= col_name","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T23:22:19.661336Z","iopub.execute_input":"2024-12-21T23:22:19.661634Z","iopub.status.idle":"2024-12-21T23:22:19.665556Z","shell.execute_reply.started":"2024-12-21T23:22:19.661610Z","shell.execute_reply":"2024-12-21T23:22:19.664661Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def display_cluster_images(cluster_id, image_paths, brand , n_cols=5):\n    print(f\"\\nCluster {cluster_id}:\")\n    n_images = len(image_paths)\n    n_rows = ceil(n_images / n_cols)\n\n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 3 * n_rows))\n    axes = axes.flatten()  # Đưa về danh sách để dễ truy cập\n\n    for i, image_path in enumerate(image_paths):\n        try:\n            image_path = '/kaggle/input/ml-data/Data/'+brand+'/'+image_path\n            img = load_img(image_path)\n            axes[i].imshow(img)\n            axes[i].set_title(os.path.basename(image_path), fontsize=8)\n            axes[i].axis(\"off\")\n        except Exception as e:\n            print(f\"Error loading image {image_path}: {e}\")\n\n    # Ẩn các ô thừa (nếu số ảnh không đủ để lấp đầy hàng cuối)\n    for j in range(i + 1, len(axes)):\n        axes[j].axis(\"off\")\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T23:31:17.371292Z","iopub.execute_input":"2024-12-21T23:31:17.371615Z","iopub.status.idle":"2024-12-21T23:31:17.377621Z","shell.execute_reply.started":"2024-12-21T23:31:17.371582Z","shell.execute_reply":"2024-12-21T23:31:17.376801Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images = car_data['Dir']\ncars_brand_set = ('Honda', 'Hyundai', 'KIA', 'Mazda', 'Mitsubishi', 'Suzuki', 'Toyota', 'VinFast', 'Others')\nfeatures = []\nimages_dir = '/kaggle/input/ml-data/Data'\nbatch_size = 8\ntransform = Compose([\n    Resize((224,224)),\n    ToTensor()\n])\n\nall_results = []\nflatten = Flatten()\nfor brand in cars_brand_set:\n    features = []\n    valid_paths = []\n    file_dir = os.path.join(images_dir, brand)\n    print(f'Processing brand: {brand}')\n    for file in os.listdir(file_dir):\n        img_dir = images_dir+'/'+brand+'/' +file\n        # img = Image.open(img_dir)\n        try:\n            img = Image.open(img_dir)\n              # Chuyển đổi sang RGB nếu thành công\n        except UnidentifiedImageError:\n            print(f\"Cannot identify image file: {img_dir}\")\n            continue\n        if img.mode == \"P\":\n            img = img.convert(\"RGB\")\n        elif img.mode == \"RGBA\":\n            img = img.convert(\"RGB\")\n        else:\n            img = img.convert(\"RGB\")\n            \n        img = img.resize((224, 224))\n        img_array = np.array(img)  # Chuyển sang NumPy array\n        img_array = preprocess_input(img_array)  # Tiền xử lý\n        img_array = np.expand_dims(img_array, axis=0)\n            \n        \n        feature = model(img_array)\n        feature = tf.keras.layers.Flatten()(feature)\n        if feature is not None:\n            feature = tf.squeeze(feature, axis=0)\n            features.append(feature)\n            valid_paths.append(file)\n    features = np.array(features)\n    print(features.shape)\n    dbscan = DBSCAN(eps=5, min_samples=2, metric='euclidean')  # eps có thể cần điều chỉnh\n    clusters = dbscan.fit_predict(features)\n\n    cluster_df = pd.DataFrame({\n        \"ImagePath\": valid_paths,\n        \"ClusterID\": clusters\n    })\n    duplicate_clusters = cluster_df[cluster_df[\"ClusterID\"] != -1].groupby(\"ClusterID\")\n    \n    for cluster_id, group in duplicate_clusters:\n        cluster_images = group[\"ImagePath\"].tolist()\n        print(f\"\\nCluster {cluster_id} (Directory: {brand}):\")\n        print(\"\\n\".join(cluster_images))\n        display_cluster_images(cluster_id, cluster_images, brand)\n\n        # Ghi kết quả vào danh sách\n        for img_path in cluster_images:\n            all_results.append({\n                \"Directory\": brand,\n                \"ClusterID\": cluster_id,\n                \"ImagePath\": img_path\n            })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T23:31:36.932760Z","iopub.execute_input":"2024-12-21T23:31:36.933068Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Giả sử bạn đã có DataFrame chứa kết quả\nresult_df = pd.DataFrame(all_results)\n\n# Đường dẫn lưu file trên Kaggle\noutput_csv = \"/kaggle/working/DuplicateDetectionResults.csv\"\n\n# Lưu DataFrame thành file CSV\nresult_df.to_csv(output_csv, index=False)\n\nprint(f\"\\nDuplicate detection results saved to {output_csv}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T10:17:34.044515Z","iopub.status.idle":"2024-12-21T10:17:34.044772Z","shell.execute_reply":"2024-12-21T10:17:34.044658Z"}},"outputs":[],"execution_count":null}]}